{
  "best_global_step": 1370,
  "best_metric": 0.16066838800907135,
  "best_model_checkpoint": "./qwen_law_assistant\\checkpoint-1370",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 1370,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.072992700729927,
      "grad_norm": 2.4360899925231934,
      "learning_rate": 1.9708029197080293e-06,
      "loss": 2.2181,
      "step": 10
    },
    {
      "epoch": 0.145985401459854,
      "grad_norm": 2.4097135066986084,
      "learning_rate": 4.160583941605839e-06,
      "loss": 2.2366,
      "step": 20
    },
    {
      "epoch": 0.21897810218978103,
      "grad_norm": 2.3598904609680176,
      "learning_rate": 6.3503649635036495e-06,
      "loss": 2.2008,
      "step": 30
    },
    {
      "epoch": 0.291970802919708,
      "grad_norm": 1.8028762340545654,
      "learning_rate": 8.540145985401459e-06,
      "loss": 2.0059,
      "step": 40
    },
    {
      "epoch": 0.36496350364963503,
      "grad_norm": 1.8429231643676758,
      "learning_rate": 1.0729927007299268e-05,
      "loss": 1.9931,
      "step": 50
    },
    {
      "epoch": 0.43795620437956206,
      "grad_norm": 1.5303587913513184,
      "learning_rate": 1.291970802919708e-05,
      "loss": 1.8508,
      "step": 60
    },
    {
      "epoch": 0.5109489051094891,
      "grad_norm": 1.2350895404815674,
      "learning_rate": 1.5109489051094889e-05,
      "loss": 1.7145,
      "step": 70
    },
    {
      "epoch": 0.583941605839416,
      "grad_norm": 0.8905909061431885,
      "learning_rate": 1.72992700729927e-05,
      "loss": 1.6213,
      "step": 80
    },
    {
      "epoch": 0.656934306569343,
      "grad_norm": 0.7328965067863464,
      "learning_rate": 1.9489051094890508e-05,
      "loss": 1.4995,
      "step": 90
    },
    {
      "epoch": 0.7299270072992701,
      "grad_norm": 0.7603882551193237,
      "learning_rate": 2.167883211678832e-05,
      "loss": 1.4477,
      "step": 100
    },
    {
      "epoch": 0.8029197080291971,
      "grad_norm": 0.7361890077590942,
      "learning_rate": 2.386861313868613e-05,
      "loss": 1.3668,
      "step": 110
    },
    {
      "epoch": 0.8759124087591241,
      "grad_norm": 0.7624443769454956,
      "learning_rate": 2.605839416058394e-05,
      "loss": 1.2601,
      "step": 120
    },
    {
      "epoch": 0.948905109489051,
      "grad_norm": 0.7169504761695862,
      "learning_rate": 2.824817518248175e-05,
      "loss": 1.2519,
      "step": 130
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.218074917793274,
      "eval_runtime": 10.7366,
      "eval_samples_per_second": 45.452,
      "eval_steps_per_second": 5.681,
      "step": 137
    },
    {
      "epoch": 1.0218978102189782,
      "grad_norm": 0.6842846274375916,
      "learning_rate": 3.0437956204379562e-05,
      "loss": 1.2242,
      "step": 140
    },
    {
      "epoch": 1.094890510948905,
      "grad_norm": 0.6837229132652283,
      "learning_rate": 3.262773722627737e-05,
      "loss": 1.1384,
      "step": 150
    },
    {
      "epoch": 1.167883211678832,
      "grad_norm": 0.8163821697235107,
      "learning_rate": 3.481751824817518e-05,
      "loss": 1.1402,
      "step": 160
    },
    {
      "epoch": 1.2408759124087592,
      "grad_norm": 0.935163140296936,
      "learning_rate": 3.700729927007299e-05,
      "loss": 1.1306,
      "step": 170
    },
    {
      "epoch": 1.313868613138686,
      "grad_norm": 0.819782555103302,
      "learning_rate": 3.91970802919708e-05,
      "loss": 1.0494,
      "step": 180
    },
    {
      "epoch": 1.3868613138686132,
      "grad_norm": 0.8047629594802856,
      "learning_rate": 4.138686131386861e-05,
      "loss": 1.0433,
      "step": 190
    },
    {
      "epoch": 1.4598540145985401,
      "grad_norm": 0.8312621712684631,
      "learning_rate": 4.3576642335766415e-05,
      "loss": 0.9947,
      "step": 200
    },
    {
      "epoch": 1.5328467153284673,
      "grad_norm": 0.8563319444656372,
      "learning_rate": 4.5766423357664235e-05,
      "loss": 0.9882,
      "step": 210
    },
    {
      "epoch": 1.6058394160583942,
      "grad_norm": 0.9897667765617371,
      "learning_rate": 4.795620437956204e-05,
      "loss": 0.932,
      "step": 220
    },
    {
      "epoch": 1.6788321167883211,
      "grad_norm": 0.9348548054695129,
      "learning_rate": 5.014598540145985e-05,
      "loss": 0.9395,
      "step": 230
    },
    {
      "epoch": 1.7518248175182483,
      "grad_norm": 0.8413358926773071,
      "learning_rate": 5.233576642335765e-05,
      "loss": 0.9224,
      "step": 240
    },
    {
      "epoch": 1.8248175182481752,
      "grad_norm": 0.9645219445228577,
      "learning_rate": 5.452554744525547e-05,
      "loss": 0.8684,
      "step": 250
    },
    {
      "epoch": 1.897810218978102,
      "grad_norm": 1.0520784854888916,
      "learning_rate": 5.671532846715328e-05,
      "loss": 0.8349,
      "step": 260
    },
    {
      "epoch": 1.9708029197080292,
      "grad_norm": 1.0935105085372925,
      "learning_rate": 5.8905109489051085e-05,
      "loss": 0.8326,
      "step": 270
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8403950929641724,
      "eval_runtime": 10.7082,
      "eval_samples_per_second": 45.572,
      "eval_steps_per_second": 5.697,
      "step": 274
    },
    {
      "epoch": 2.0437956204379564,
      "grad_norm": 1.0326091051101685,
      "learning_rate": 6.10948905109489e-05,
      "loss": 0.8057,
      "step": 280
    },
    {
      "epoch": 2.116788321167883,
      "grad_norm": 1.132171869277954,
      "learning_rate": 6.32846715328467e-05,
      "loss": 0.7715,
      "step": 290
    },
    {
      "epoch": 2.18978102189781,
      "grad_norm": 1.3393272161483765,
      "learning_rate": 6.547445255474451e-05,
      "loss": 0.7629,
      "step": 300
    },
    {
      "epoch": 2.2627737226277373,
      "grad_norm": 1.216813325881958,
      "learning_rate": 6.766423357664233e-05,
      "loss": 0.7398,
      "step": 310
    },
    {
      "epoch": 2.335766423357664,
      "grad_norm": 1.3465577363967896,
      "learning_rate": 6.985401459854014e-05,
      "loss": 0.7281,
      "step": 320
    },
    {
      "epoch": 2.408759124087591,
      "grad_norm": 1.3234577178955078,
      "learning_rate": 7.204379562043794e-05,
      "loss": 0.6784,
      "step": 330
    },
    {
      "epoch": 2.4817518248175183,
      "grad_norm": 1.3565673828125,
      "learning_rate": 7.423357664233576e-05,
      "loss": 0.6774,
      "step": 340
    },
    {
      "epoch": 2.554744525547445,
      "grad_norm": 1.4046030044555664,
      "learning_rate": 7.642335766423357e-05,
      "loss": 0.6449,
      "step": 350
    },
    {
      "epoch": 2.627737226277372,
      "grad_norm": 1.3836652040481567,
      "learning_rate": 7.861313868613137e-05,
      "loss": 0.6447,
      "step": 360
    },
    {
      "epoch": 2.7007299270072993,
      "grad_norm": 1.4560495615005493,
      "learning_rate": 8.080291970802918e-05,
      "loss": 0.6145,
      "step": 370
    },
    {
      "epoch": 2.7737226277372264,
      "grad_norm": 1.5744011402130127,
      "learning_rate": 8.299270072992699e-05,
      "loss": 0.631,
      "step": 380
    },
    {
      "epoch": 2.846715328467153,
      "grad_norm": 1.4546006917953491,
      "learning_rate": 8.518248175182482e-05,
      "loss": 0.5713,
      "step": 390
    },
    {
      "epoch": 2.9197080291970803,
      "grad_norm": 1.8176405429840088,
      "learning_rate": 8.737226277372262e-05,
      "loss": 0.5405,
      "step": 400
    },
    {
      "epoch": 2.9927007299270074,
      "grad_norm": 1.8010326623916626,
      "learning_rate": 8.956204379562043e-05,
      "loss": 0.5442,
      "step": 410
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.5549813508987427,
      "eval_runtime": 10.6701,
      "eval_samples_per_second": 45.735,
      "eval_steps_per_second": 5.717,
      "step": 411
    },
    {
      "epoch": 3.065693430656934,
      "grad_norm": 1.5782952308654785,
      "learning_rate": 9.175182481751824e-05,
      "loss": 0.5064,
      "step": 420
    },
    {
      "epoch": 3.1386861313868613,
      "grad_norm": 1.8876911401748657,
      "learning_rate": 9.394160583941604e-05,
      "loss": 0.4936,
      "step": 430
    },
    {
      "epoch": 3.2116788321167884,
      "grad_norm": 1.796931266784668,
      "learning_rate": 9.613138686131385e-05,
      "loss": 0.4825,
      "step": 440
    },
    {
      "epoch": 3.2846715328467155,
      "grad_norm": 1.7820302248001099,
      "learning_rate": 9.832116788321168e-05,
      "loss": 0.4473,
      "step": 450
    },
    {
      "epoch": 3.3576642335766422,
      "grad_norm": 1.815171241760254,
      "learning_rate": 0.00010051094890510949,
      "loss": 0.4572,
      "step": 460
    },
    {
      "epoch": 3.4306569343065694,
      "grad_norm": 1.691260576248169,
      "learning_rate": 0.0001027007299270073,
      "loss": 0.4456,
      "step": 470
    },
    {
      "epoch": 3.5036496350364965,
      "grad_norm": 2.0511624813079834,
      "learning_rate": 0.0001048905109489051,
      "loss": 0.4318,
      "step": 480
    },
    {
      "epoch": 3.576642335766423,
      "grad_norm": 1.708763599395752,
      "learning_rate": 0.0001070802919708029,
      "loss": 0.4145,
      "step": 490
    },
    {
      "epoch": 3.6496350364963503,
      "grad_norm": 1.6390389204025269,
      "learning_rate": 0.00010927007299270071,
      "loss": 0.4012,
      "step": 500
    },
    {
      "epoch": 3.7226277372262775,
      "grad_norm": 1.684267520904541,
      "learning_rate": 0.00011145985401459853,
      "loss": 0.3822,
      "step": 510
    },
    {
      "epoch": 3.795620437956204,
      "grad_norm": 1.7905144691467285,
      "learning_rate": 0.00011364963503649634,
      "loss": 0.3754,
      "step": 520
    },
    {
      "epoch": 3.8686131386861313,
      "grad_norm": 1.613369345664978,
      "learning_rate": 0.00011583941605839416,
      "loss": 0.355,
      "step": 530
    },
    {
      "epoch": 3.9416058394160585,
      "grad_norm": 1.8150410652160645,
      "learning_rate": 0.00011802919708029196,
      "loss": 0.3453,
      "step": 540
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.3576478064060211,
      "eval_runtime": 10.6838,
      "eval_samples_per_second": 45.676,
      "eval_steps_per_second": 5.71,
      "step": 548
    },
    {
      "epoch": 4.014598540145985,
      "grad_norm": 1.5770937204360962,
      "learning_rate": 0.00012021897810218977,
      "loss": 0.3259,
      "step": 550
    },
    {
      "epoch": 4.087591240875913,
      "grad_norm": 1.561550498008728,
      "learning_rate": 0.00012240875912408758,
      "loss": 0.3116,
      "step": 560
    },
    {
      "epoch": 4.160583941605839,
      "grad_norm": 1.5794683694839478,
      "learning_rate": 0.0001245985401459854,
      "loss": 0.3045,
      "step": 570
    },
    {
      "epoch": 4.233576642335766,
      "grad_norm": 1.4611586332321167,
      "learning_rate": 0.00012678832116788322,
      "loss": 0.2892,
      "step": 580
    },
    {
      "epoch": 4.306569343065694,
      "grad_norm": 1.633256435394287,
      "learning_rate": 0.00012897810218978102,
      "loss": 0.2964,
      "step": 590
    },
    {
      "epoch": 4.37956204379562,
      "grad_norm": 1.3335249423980713,
      "learning_rate": 0.00013116788321167883,
      "loss": 0.2825,
      "step": 600
    },
    {
      "epoch": 4.452554744525547,
      "grad_norm": 1.3333487510681152,
      "learning_rate": 0.00013335766423357663,
      "loss": 0.2825,
      "step": 610
    },
    {
      "epoch": 4.525547445255475,
      "grad_norm": 1.4505678415298462,
      "learning_rate": 0.00013554744525547444,
      "loss": 0.2644,
      "step": 620
    },
    {
      "epoch": 4.598540145985401,
      "grad_norm": 1.7673592567443848,
      "learning_rate": 0.00013773722627737225,
      "loss": 0.2629,
      "step": 630
    },
    {
      "epoch": 4.671532846715328,
      "grad_norm": 1.5080766677856445,
      "learning_rate": 0.00013992700729927008,
      "loss": 0.2685,
      "step": 640
    },
    {
      "epoch": 4.744525547445256,
      "grad_norm": 1.5006150007247925,
      "learning_rate": 0.00014211678832116789,
      "loss": 0.254,
      "step": 650
    },
    {
      "epoch": 4.817518248175182,
      "grad_norm": 1.211166501045227,
      "learning_rate": 0.0001443065693430657,
      "loss": 0.2547,
      "step": 660
    },
    {
      "epoch": 4.89051094890511,
      "grad_norm": 1.5585930347442627,
      "learning_rate": 0.0001464963503649635,
      "loss": 0.2463,
      "step": 670
    },
    {
      "epoch": 4.963503649635037,
      "grad_norm": 1.3389736413955688,
      "learning_rate": 0.0001486861313868613,
      "loss": 0.2354,
      "step": 680
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.24160882830619812,
      "eval_runtime": 10.6814,
      "eval_samples_per_second": 45.687,
      "eval_steps_per_second": 5.711,
      "step": 685
    },
    {
      "epoch": 5.036496350364963,
      "grad_norm": 1.2656700611114502,
      "learning_rate": 0.0001508759124087591,
      "loss": 0.2321,
      "step": 690
    },
    {
      "epoch": 5.109489051094891,
      "grad_norm": 1.4920405149459839,
      "learning_rate": 0.00015306569343065692,
      "loss": 0.2205,
      "step": 700
    },
    {
      "epoch": 5.182481751824818,
      "grad_norm": 1.4018864631652832,
      "learning_rate": 0.00015525547445255472,
      "loss": 0.2148,
      "step": 710
    },
    {
      "epoch": 5.255474452554744,
      "grad_norm": 1.4568908214569092,
      "learning_rate": 0.00015744525547445253,
      "loss": 0.2217,
      "step": 720
    },
    {
      "epoch": 5.328467153284672,
      "grad_norm": 1.1390880346298218,
      "learning_rate": 0.00015963503649635036,
      "loss": 0.214,
      "step": 730
    },
    {
      "epoch": 5.401459854014599,
      "grad_norm": 1.2351113557815552,
      "learning_rate": 0.00016182481751824817,
      "loss": 0.2123,
      "step": 740
    },
    {
      "epoch": 5.474452554744525,
      "grad_norm": 1.0589088201522827,
      "learning_rate": 0.00016401459854014597,
      "loss": 0.2138,
      "step": 750
    },
    {
      "epoch": 5.547445255474453,
      "grad_norm": 1.4187525510787964,
      "learning_rate": 0.00016620437956204378,
      "loss": 0.2148,
      "step": 760
    },
    {
      "epoch": 5.62043795620438,
      "grad_norm": 1.0902942419052124,
      "learning_rate": 0.00016839416058394158,
      "loss": 0.2079,
      "step": 770
    },
    {
      "epoch": 5.693430656934306,
      "grad_norm": 1.2102855443954468,
      "learning_rate": 0.0001705839416058394,
      "loss": 0.2013,
      "step": 780
    },
    {
      "epoch": 5.766423357664234,
      "grad_norm": 1.1092053651809692,
      "learning_rate": 0.0001727737226277372,
      "loss": 0.2018,
      "step": 790
    },
    {
      "epoch": 5.839416058394161,
      "grad_norm": 1.514769434928894,
      "learning_rate": 0.00017496350364963503,
      "loss": 0.2022,
      "step": 800
    },
    {
      "epoch": 5.912408759124087,
      "grad_norm": 1.1678801774978638,
      "learning_rate": 0.00017715328467153284,
      "loss": 0.1913,
      "step": 810
    },
    {
      "epoch": 5.985401459854015,
      "grad_norm": 1.0509440898895264,
      "learning_rate": 0.00017934306569343064,
      "loss": 0.192,
      "step": 820
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.19686271250247955,
      "eval_runtime": 10.7124,
      "eval_samples_per_second": 45.555,
      "eval_steps_per_second": 5.694,
      "step": 822
    },
    {
      "epoch": 6.0583941605839415,
      "grad_norm": 0.8973808884620667,
      "learning_rate": 0.00018153284671532845,
      "loss": 0.1864,
      "step": 830
    },
    {
      "epoch": 6.131386861313868,
      "grad_norm": 1.0279685258865356,
      "learning_rate": 0.00018372262773722625,
      "loss": 0.1842,
      "step": 840
    },
    {
      "epoch": 6.204379562043796,
      "grad_norm": 0.9090372323989868,
      "learning_rate": 0.0001859124087591241,
      "loss": 0.1854,
      "step": 850
    },
    {
      "epoch": 6.2773722627737225,
      "grad_norm": 0.816420316696167,
      "learning_rate": 0.0001881021897810219,
      "loss": 0.1839,
      "step": 860
    },
    {
      "epoch": 6.350364963503649,
      "grad_norm": 0.8243935108184814,
      "learning_rate": 0.0001902919708029197,
      "loss": 0.1875,
      "step": 870
    },
    {
      "epoch": 6.423357664233577,
      "grad_norm": 0.9172778129577637,
      "learning_rate": 0.0001924817518248175,
      "loss": 0.1797,
      "step": 880
    },
    {
      "epoch": 6.4963503649635035,
      "grad_norm": 0.8465563058853149,
      "learning_rate": 0.0001946715328467153,
      "loss": 0.1833,
      "step": 890
    },
    {
      "epoch": 6.569343065693431,
      "grad_norm": 0.7145264148712158,
      "learning_rate": 0.00019686131386861312,
      "loss": 0.1811,
      "step": 900
    },
    {
      "epoch": 6.642335766423358,
      "grad_norm": 0.8094483017921448,
      "learning_rate": 0.00019905109489051092,
      "loss": 0.1737,
      "step": 910
    },
    {
      "epoch": 6.7153284671532845,
      "grad_norm": 0.9955232739448547,
      "learning_rate": 0.00020124087591240873,
      "loss": 0.1811,
      "step": 920
    },
    {
      "epoch": 6.788321167883212,
      "grad_norm": 0.7370069622993469,
      "learning_rate": 0.00020343065693430654,
      "loss": 0.1807,
      "step": 930
    },
    {
      "epoch": 6.861313868613139,
      "grad_norm": 0.76749587059021,
      "learning_rate": 0.00020562043795620434,
      "loss": 0.176,
      "step": 940
    },
    {
      "epoch": 6.934306569343065,
      "grad_norm": 1.0971826314926147,
      "learning_rate": 0.00020781021897810215,
      "loss": 0.175,
      "step": 950
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.17874126136302948,
      "eval_runtime": 10.6949,
      "eval_samples_per_second": 45.629,
      "eval_steps_per_second": 5.704,
      "step": 959
    },
    {
      "epoch": 7.007299270072993,
      "grad_norm": 0.7930602431297302,
      "learning_rate": 0.00020999999999999998,
      "loss": 0.1768,
      "step": 960
    },
    {
      "epoch": 7.08029197080292,
      "grad_norm": 0.5961068272590637,
      "learning_rate": 0.0002121897810218978,
      "loss": 0.1732,
      "step": 970
    },
    {
      "epoch": 7.153284671532846,
      "grad_norm": 0.9087877869606018,
      "learning_rate": 0.00021437956204379562,
      "loss": 0.1672,
      "step": 980
    },
    {
      "epoch": 7.226277372262774,
      "grad_norm": 0.6478674411773682,
      "learning_rate": 0.00021656934306569343,
      "loss": 0.167,
      "step": 990
    },
    {
      "epoch": 7.299270072992701,
      "grad_norm": 0.7277055382728577,
      "learning_rate": 0.00021875912408759123,
      "loss": 0.1655,
      "step": 1000
    },
    {
      "epoch": 7.372262773722627,
      "grad_norm": 0.5690528154373169,
      "learning_rate": 0.00022094890510948904,
      "loss": 0.1659,
      "step": 1010
    },
    {
      "epoch": 7.445255474452555,
      "grad_norm": 0.5092752575874329,
      "learning_rate": 0.00022313868613138685,
      "loss": 0.1637,
      "step": 1020
    },
    {
      "epoch": 7.518248175182482,
      "grad_norm": 0.617233157157898,
      "learning_rate": 0.00022532846715328465,
      "loss": 0.1694,
      "step": 1030
    },
    {
      "epoch": 7.591240875912408,
      "grad_norm": 0.6547703146934509,
      "learning_rate": 0.00022751824817518246,
      "loss": 0.1609,
      "step": 1040
    },
    {
      "epoch": 7.664233576642336,
      "grad_norm": 0.6925713419914246,
      "learning_rate": 0.00022970802919708026,
      "loss": 0.1649,
      "step": 1050
    },
    {
      "epoch": 7.737226277372263,
      "grad_norm": 0.6229216456413269,
      "learning_rate": 0.00023189781021897807,
      "loss": 0.1647,
      "step": 1060
    },
    {
      "epoch": 7.81021897810219,
      "grad_norm": 0.6139057278633118,
      "learning_rate": 0.00023408759124087588,
      "loss": 0.1674,
      "step": 1070
    },
    {
      "epoch": 7.883211678832117,
      "grad_norm": 0.5501114726066589,
      "learning_rate": 0.00023627737226277368,
      "loss": 0.165,
      "step": 1080
    },
    {
      "epoch": 7.956204379562044,
      "grad_norm": 0.551881730556488,
      "learning_rate": 0.0002384671532846715,
      "loss": 0.1627,
      "step": 1090
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.16356810927391052,
      "eval_runtime": 10.6807,
      "eval_samples_per_second": 45.69,
      "eval_steps_per_second": 5.711,
      "step": 1096
    },
    {
      "epoch": 8.02919708029197,
      "grad_norm": 0.3776741623878479,
      "learning_rate": 0.00024065693430656935,
      "loss": 0.1589,
      "step": 1100
    },
    {
      "epoch": 8.102189781021897,
      "grad_norm": 0.43170955777168274,
      "learning_rate": 0.00024284671532846715,
      "loss": 0.1598,
      "step": 1110
    },
    {
      "epoch": 8.175182481751825,
      "grad_norm": 0.5745799541473389,
      "learning_rate": 0.00024503649635036496,
      "loss": 0.16,
      "step": 1120
    },
    {
      "epoch": 8.248175182481752,
      "grad_norm": 0.45961931347846985,
      "learning_rate": 0.00024722627737226277,
      "loss": 0.1654,
      "step": 1130
    },
    {
      "epoch": 8.321167883211679,
      "grad_norm": 0.44194746017456055,
      "learning_rate": 0.00024941605839416057,
      "loss": 0.1529,
      "step": 1140
    },
    {
      "epoch": 8.394160583941606,
      "grad_norm": 0.4771580994129181,
      "learning_rate": 0.0002516058394160584,
      "loss": 0.1648,
      "step": 1150
    },
    {
      "epoch": 8.467153284671532,
      "grad_norm": 0.6624618768692017,
      "learning_rate": 0.0002537956204379562,
      "loss": 0.1619,
      "step": 1160
    },
    {
      "epoch": 8.540145985401459,
      "grad_norm": 0.6312896013259888,
      "learning_rate": 0.000255985401459854,
      "loss": 0.16,
      "step": 1170
    },
    {
      "epoch": 8.613138686131387,
      "grad_norm": 0.5556868314743042,
      "learning_rate": 0.0002581751824817518,
      "loss": 0.161,
      "step": 1180
    },
    {
      "epoch": 8.686131386861314,
      "grad_norm": 0.5640411376953125,
      "learning_rate": 0.0002603649635036496,
      "loss": 0.1573,
      "step": 1190
    },
    {
      "epoch": 8.75912408759124,
      "grad_norm": 0.5352436900138855,
      "learning_rate": 0.0002625547445255474,
      "loss": 0.1597,
      "step": 1200
    },
    {
      "epoch": 8.832116788321168,
      "grad_norm": 0.4833813011646271,
      "learning_rate": 0.0002647445255474452,
      "loss": 0.162,
      "step": 1210
    },
    {
      "epoch": 8.905109489051094,
      "grad_norm": 0.6203252673149109,
      "learning_rate": 0.000266934306569343,
      "loss": 0.1614,
      "step": 1220
    },
    {
      "epoch": 8.978102189781023,
      "grad_norm": 0.6243705153465271,
      "learning_rate": 0.0002691240875912409,
      "loss": 0.1604,
      "step": 1230
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.1612928956747055,
      "eval_runtime": 10.6839,
      "eval_samples_per_second": 45.676,
      "eval_steps_per_second": 5.71,
      "step": 1233
    },
    {
      "epoch": 9.05109489051095,
      "grad_norm": 0.47685596346855164,
      "learning_rate": 0.0002713138686131387,
      "loss": 0.1588,
      "step": 1240
    },
    {
      "epoch": 9.124087591240876,
      "grad_norm": 0.5340838432312012,
      "learning_rate": 0.0002735036496350365,
      "loss": 0.1598,
      "step": 1250
    },
    {
      "epoch": 9.197080291970803,
      "grad_norm": 0.48795822262763977,
      "learning_rate": 0.0002756934306569343,
      "loss": 0.1619,
      "step": 1260
    },
    {
      "epoch": 9.27007299270073,
      "grad_norm": 0.5433540940284729,
      "learning_rate": 0.0002778832116788321,
      "loss": 0.1591,
      "step": 1270
    },
    {
      "epoch": 9.343065693430656,
      "grad_norm": 0.508553147315979,
      "learning_rate": 0.0002800729927007299,
      "loss": 0.1611,
      "step": 1280
    },
    {
      "epoch": 9.416058394160585,
      "grad_norm": 0.5464178919792175,
      "learning_rate": 0.0002822627737226277,
      "loss": 0.1583,
      "step": 1290
    },
    {
      "epoch": 9.489051094890511,
      "grad_norm": 0.5330556035041809,
      "learning_rate": 0.0002844525547445255,
      "loss": 0.1599,
      "step": 1300
    },
    {
      "epoch": 9.562043795620438,
      "grad_norm": 0.5783399343490601,
      "learning_rate": 0.00028664233576642333,
      "loss": 0.1588,
      "step": 1310
    },
    {
      "epoch": 9.635036496350365,
      "grad_norm": 0.5542641878128052,
      "learning_rate": 0.00028883211678832114,
      "loss": 0.1602,
      "step": 1320
    },
    {
      "epoch": 9.708029197080291,
      "grad_norm": 0.5392045378684998,
      "learning_rate": 0.00029102189781021894,
      "loss": 0.1542,
      "step": 1330
    },
    {
      "epoch": 9.78102189781022,
      "grad_norm": 0.3811491131782532,
      "learning_rate": 0.00029321167883211675,
      "loss": 0.1618,
      "step": 1340
    },
    {
      "epoch": 9.854014598540147,
      "grad_norm": 0.5345106720924377,
      "learning_rate": 0.0002954014598540146,
      "loss": 0.1588,
      "step": 1350
    },
    {
      "epoch": 9.927007299270073,
      "grad_norm": 0.5128337740898132,
      "learning_rate": 0.0002975912408759124,
      "loss": 0.1581,
      "step": 1360
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.40508395433425903,
      "learning_rate": 0.0002997810218978102,
      "loss": 0.1611,
      "step": 1370
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.16066838800907135,
      "eval_runtime": 10.6802,
      "eval_samples_per_second": 45.692,
      "eval_steps_per_second": 5.712,
      "step": 1370
    }
  ],
  "logging_steps": 10,
  "max_steps": 13700,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.97201486788608e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
