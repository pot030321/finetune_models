2025-08-13 08:58:34,336 - INFO - Loading model and tokenizer from Qwen/Qwen2.5-0.5B...
2025-08-13 08:58:35,444 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
